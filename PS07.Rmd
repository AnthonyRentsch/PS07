---
title: "STAT/MATH 495: Problem Set 07"
author: "Anthony Rentsch"
date: "2017-10-24"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(broom)
library(knitr)
library(magrittr)
library(ROCR)

train <- read.csv("data/cs-training.csv") %>% 
  rename(Id = X)
test <- read.csv("data/cs-test.csv") %>% 
  rename(Id = X)
submission <- read_csv("data/sampleEntry.csv")
```

Information on the competition can be found [here](https://www.kaggle.com/c/GiveMeSomeCredit/data).



# Exploring the data


Distribution of age, monthly income, and debt ratio for whether or not a person experienced 90 days past due delinquency or worse. Recall that 0 means the person $has\ not$ experienced this, while 1 means the person $has$ experienced this. The histograms for `MonthlyIncome` and `DebtRatio` are slightly zoomed in to make them easier to interpret, which means a few outliers are excluded.

```{r, echo = FALSE}
train %>% filter(!is.na(age)) %>% 
  ggplot() +
  geom_histogram(aes(age), binwidth = 2) +
  facet_wrap(~SeriousDlqin2yrs, ncol = 1)
```

```{r, echo = FALSE}
train %>% filter(!is.na(MonthlyIncome)) %>% 
  ggplot() +
  geom_histogram(aes(MonthlyIncome), binwidth = 1000) +
  facet_wrap(~SeriousDlqin2yrs, ncol = 1) +
  coord_cartesian(xlim = c(0, 150000), ylim = c(0, 30000))
```

```{r, echo = FALSE}
train %>% filter(!is.na(DebtRatio)) %>% 
  ggplot() +
  geom_histogram(aes(DebtRatio), binwidth = 1000) +
  facet_wrap(~SeriousDlqin2yrs, ncol = 1) +
  coord_cartesian(xlim = c(0, 50000), ylim = c(0, 10000))
```




# Build binary classifier


Based on the histograms above, the distributions of ages of those who have experienced 90 days past due delinquency or worse and those who have not are more different than the distributions of debt ratios or monthly incomes. Thus, it is reasonable to believe a binary classifier based on age will do the best at classifying individuals.


```{r}
model <- glm(SeriousDlqin2yrs ~ age, data = train, family="binomial")

model %>% 
  broom::tidy(conf.int = TRUE)
```

Here is a quick look at what the output looks like when we use this model to make predictions with the test set.

```{r, echo = FALSE}
model %>% 
  broom::augment(newdata = test) %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted))) %>% 
  select(Id, age, .fitted, .se.fit, p_hat) %>% 
  sample_n(5)
```


Let's visualize what this model looks like. The predicted probability of experiencing 90 days past due delinquency or worse is inversely related to a person's age; younger people are more likely to experience it while older people are less likely. 

```{r, echo = FALSE}
fitted_model <- model %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted)))
predictions <- model %>% 
  broom::augment(newdata = test) %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted)))

# Visualize the logistic regression in log-odds(p) space
ggplot(NULL) +
  geom_line(data = fitted_model, aes(x = age, y = .fitted), col="blue") +
  geom_point(data = predictions, aes(x = age, y = .fitted), col="red") +
  labs(x="age (in years)", y="Fitted log-odds of p_hat", title="Fitted log-odds of probability of experiencing 90 days past due delinquency or worse vs age")
```

Let's also take a look at the distribution of `p_hat` values, for both the training and test set. The grey bars correspond to the training set, while the blue bars correspond to the test set. Fitted probabilities of experiencing 90 days past due delinquency or worse range between roughly 1% and 15% for test data, and 1% and 27% for training data.

```{r, echo = FALSE}
ggplot() +
  geom_histogram(data = fitted_model, aes(p_hat), fill = "grey") +
  geom_histogram(data = predictions, aes(p_hat), fill = "darkblue") +
  labs(title = "Distribution of p_hat")
```


# ROC curve

Now I will calculate the AUC and plot an ROC curve based on this model.

```{r}
train_augmented <- model %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1+exp(-.fitted)))

# This bit of code computes the ROC curve
pred <- prediction(predictions = train_augmented$p_hat, labels = train_augmented$SeriousDlqin2yrs)
perf <- performance(pred, "tpr","fpr")

# This bit of code computes the Area Under the Curve
auc <- as.numeric(performance(pred,"auc")@y.values)
auc
```

```{r}
plot(perf, main = paste("Area Under the Curve =", round(auc, 3)))
abline(c(0, 1), lty = 2)
```

This suggests that my model did a bit better than random guessing, although not by a whole lot.

# ROC curve for random guessing

Now, I will switch to making predictions using random guesses and plot the resulting ROC curve.

```{r, echo = FALSE}
set.seed(100)

random <- train %>% select(Id, SeriousDlqin2yrs) %>% rowwise() %>% mutate(p_hat = runif(1))

# This bit of code computes the ROC curve
pred <- prediction(predictions = random$p_hat, labels = random$SeriousDlqin2yrs)
perf <- performance(pred, "tpr","fpr")

# This bit of code computes the Area Under the Curve
auc <- as.numeric(performance(pred,"auc")@y.values)

#plot curve
plot(perf, main = paste("Area Under the Curve =", round(auc, 3)))
abline(c(0, 1), lty=2)
```

This checks out - the ROC curve created by random guesses should be roughly identical to the diagonal reference line, which it is.

# Creating submission files

$Logistic\ regression\ model$

```{r}
submit <- predictions %>% select(Id = Id, Probability = p_hat)
write.csv(submit, file = "log_submission.csv", row.names = F)
```

$Random\ guesses$

```{r}
submit.2 <- test %>% select(Id) %>% rowwise() %>% mutate(Probability = runif(1))
write.csv(submit.2, file = "random_submission.csv", row.names = F)
```

To sum up, the Kaggle scores (the AUCs) I receieved were:

* Logistic regression model: 0.637890
* Random guesses: 0.508025